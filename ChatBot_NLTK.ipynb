{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f95dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6669dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing library\n",
    "import io\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c665d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular', quiet=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd88765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # first-time use only\n",
    "nltk.download('wordnet') # first-time use only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60411ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('chatbot_NLTK.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw = raw.lower()# converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c9f5bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\thi there!  how can i help you today?\n",
      "hi\they there!  what would you like to talk about?\n",
      "how are you?\ti'm doing great, thanks for asking! how about you?\n",
      "good\tthat's fantastic to hear! \n",
      "bad\toh no, sorry to hear that.   is there anything i can help you with?\n",
      "what's your name?\tmy name is bard, your friendly chatbot assistant. \n",
      "what can you do?\ti can answer simple questions, have basic conversations, and try my best to be helpful. \n",
      "morning\tgood morning! â˜€ï¸\n",
      "evening\tgood evening!  \n",
      "what's the weather like?\ti can't access weather information yet, but i'm learning! \n",
      "what time is it?\t(implement logic to retrieve current time and display it)\n",
      "tell me a joke\twhy did the scarecrow win an award? because he was outstanding in his field! \n",
      "what is the capital of france?\tthe capital of france is paris. ðÿ‡«ðÿ‡·\n",
      "can you translate something for me?\ti can't translate languages yet, but i'm getting there!\n",
      "bye\tsee you later!  take care!\n",
      "exit\tthanks for chatting!  until next time!\n",
      "see ya\tsee you later! \n",
      "later\ttalk to you soon!  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f328f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d6a0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9ac2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\n",
    "    \"hello\", \"hi\", \"greetings\", \"sup\", \n",
    "    \"what's up\", \"hey\", \"yo\", \"what's good\", \"howdy\",\n",
    "    \"good morning\", \"good afternoon\", \"good evening\"\n",
    ")\n",
    "\n",
    "GREETING_RESPONSES = [\n",
    "    \"hi\", \"hey\", \"hi there\", \"hello\", \"I am glad you're talking to me!\",\n",
    "    \"Yo yourself!\", \"It's good to hear from you!\", \"Woohoo! It's great to chat with you!\",\n",
    "    \"Hey there! What can I do for you today?\", \n",
    "]\n",
    "\n",
    "def greeting(sentence):\n",
    "  for word in sentence.split():\n",
    "    if word.lower() in GREETING_INPUTS:\n",
    "      return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "699c4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the response\n",
    "def response(user_response):\n",
    "\n",
    " \n",
    "  user_response=user_response.lower()\n",
    "  robo_response='' #set bot response to an empty string\n",
    "  sent_tokens.append(user_response)#append the user response to a sentence list\n",
    "\n",
    "  # print the sentence list after appending user resposne\n",
    "  #create a tfidfvectorizer object\n",
    "  TfidfVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
    "  tfidf=TfidfVec.fit_transform(sent_tokens) #convert text to a metrix of Tf-idf features\n",
    "  \n",
    "  #get the measure of similarity (similarity scores)\n",
    "  vals=cosine_similarity(tfidf[-1],tfidf)\n",
    "\n",
    "  # get the index of most similar text/sentence to the user response\n",
    "  idx=vals.argsort()[0][-2]\n",
    "  flat= vals.flatten() #reduce the dimensionality of vals\n",
    "  flat.sort()#sort the list in ascending order\n",
    "  score= flat[-2] #get the most similar score to user response\n",
    "\n",
    "  #if the variable score is 0 then there is no text similar to the users response\n",
    "  if (score==0):\n",
    "    robo_response = robo_response+\"I apologies I dont understand\"\n",
    "  else:\n",
    "    robo_response=robo_response+sent_tokens[idx]\n",
    "\n",
    "  sent_tokens.remove(user_response)\n",
    "  return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3015cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"ROBO: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"ROBO: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"ROBO: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "#                 sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBO: Bye! take care..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f401f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8d8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
